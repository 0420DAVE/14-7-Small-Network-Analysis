---
title: "Empathy and Language: Network Analysis"
author: "Li Ying"
date: "12 July 2015"
output: html_document
---
```{r load data,echo=FALSE,message=FALSE}
library(xlsx); library(hash); library(dplyr); library(ggplot2); library(corrplot);library(vegan);library(igraph);library(BSDA);library(wordcloud)
setwd("~/Dropbox/#0")
source("global.R")


# Load data
word<-read.xlsx("./data.xlsx",sheetIndex=4,header=FALSE,colIndex=2:1000,rowIndex=4:76)
#word<-read.xlsx("./data.xlsx",sheetIndex=4,header=FALSE,colIndex=2:1000,rowIndex=4:76)
cues<-1:73
word<-data.frame(cue=cues,word)


# Process Empathy data 
empathy<-read.xlsx("./data.xlsx", sheetIndex=3, header=T, colIndex=2:31, rowIndex=3:36)
colnames(empathy)<-1:30
# remove participants with invalid input
empathy<-empathy[-c(6,21),]
# convert all column to numeirc
empathy[,20]<-as.numeric(empathy[,20]);empathy[,17]<-as.numeric(empathy[,17])
# Invert score of question 4, 9, 13, 16, 20, 27
empathy[,c(4,9,13,16,20,27)]<-6-empathy[,c(4,9,13,16,20,27)]
# Calculate mean following scoring instruction
empathy<-mutate(empathy,
                agg=round(apply( empathy,1,mean),digit=2),
                suffer=round(apply( empathy[,c(3,5,6,8,12,18,24,28)],1,mean),digit=2),
                positive.sharing=round(apply( empathy[,c(14, 22, 23, 29, 30)],1,mean),digit=2),
                responsive.crying=round(apply( empathy[,c(1,20,25)],1,mean),digit=2),
                emotional.attention=round(apply( empathy[,c(4,9,13,27)],1,mean),digit=2),
                fell.for.others=round(apply( empathy[,c(10,16,15,21)],1,mean),digit=2),
                emotional.contagion=round(apply( empathy[,c(11,17)],1,mean),digit=2)
                )

empathy<-empathy[,31:37]
```

### Executive Summary 
- This report performed exploratory analysis on language pattern produced by two groups of people: `High Empathy Group` and `Low Empathy Group` (refer to as High Group (HG) and Low Group (LG) in the following text)
- Word Cloud, Minimum spanning tree, hierarchical clustering graph, and association network were plotted. 
- In the end, statistical test were performed on parameters of association network using *partial network analysis / bootstrape with 1000 iteration*. Detailed steps can be found in the appendix.
- Statistical testing method refers to paper written by [Kenett, Gold and Faust( 2015)](http://scottbarrykaufman.com/wp-content/uploads/2015/06/Kenett-Gold-and-Faust-2015.pdf). Parameters of association network includes: **Diameter(D)**, [Clustering Coefficient(CC)](http://mathinsight.org/definition/clustering_coefficient), [Average Path Length(APL)](http://mathinsight.org/definition/network_mean_path_length).
The detailed definition of these concepts can be found in the `appendix`. 

#### We found that:
- t-test shows that D and APL are significantally different between EG and IG (p.value<0.01), while CC shows marginal significance (p.value=0.07).

### Data Source
- Participant number: 33
- `Multi-Dimensional Emotional Scale of Empathy`: 30 questions with 6 questions to be reversed to reduce bias. [Scoreing instruction](http://www.unh.edu/emotional_intelligence/EI%20Assets/Emapthy%20Scale/Empathy%20Article%202000.doc)
- `Free Association task`: each participants were given 73 **cue words**. For each of cue words, they were instructed to write down 3 words/**responses** that they think is most relevant to the **cue words**. The result will be mentioned as **word data** in the following text.

### Data Process
- Empathy scale were averaged for each participants. Participants were categorized into High empathy group and Low empathy group using group mean as cut-off line. 
- Steps 2, 3, 4 are identical to `Free Will and Language: Network Analysis`.

###### The distribution of empathy scale follows normal distribution

```{r test normality,echo=FALSE,message=FALSE,fig.height=4, fig.width=8, warning=FALSE, error=FALSE}

par(mfrow=c(1,2))
hist(empathy$agg,breaks=6,main="Average Empathy Score",xlab="empathy",col="steelblue",border =1); qqnorm(empathy$agg,col="steelblue");qqline(empathy$agg,col="red")
```

```{r prepare data,echo=FALSE,message=FALSE}

for (i in 1:31){
  if (empathy$agg[i] > mean(empathy$agg)){
    empathy$ctg[i]<-"High"
  }else{
    empathy$ctg[i]<-"Low"
  }
}
#table(empathy$ctg)
Hindex<-which (empathy$ctg %in% "High")
Lindex<-which (empathy$ctg %in% "Low")

# Transform index to fit `word` dataset 
f<-function(x){
  c(3*(x-1)+1, 3*(x-1)+2,3*x)}

Hindex<-f(Hindex)
Lindex<-f(Lindex)

# Remove participants 6 and 21 from word dataset
word<-word[,-c(f(c(6,21)) )]

# split word data by high/low empathy score
Hword<-word[,c(1,Hindex+1)]
Lword<-word[,c(1,Lindex+1)]

#Hindex<-sample(1:93,47) #
#Lindex<-c(1:93)[-Hindex] #
#Hword<-word[,c(1,Hindex+1)] #
#Lword<-word[,c(1,Lindex+1)] #

Hfreq<-process(Hword)
Lfreq<-process(Lword)
freq<-process(word)
histoplot(freq)

```

### Exploratory Data Analysis

#### Word Cloud
```{r}
par(mar=c(5,2,1,1))
par(mfrow=c(1,2))
cloud(Hfreq)
cloud(Lfreq)
```

#### Clustering Analysis (single linkage)
Cluster Dendrogram were plotted. Both groups shows that most clue words merges at a high y-axis, suggesting similarity between clue words are quite low. 
```{r  Clustering Analysis,echo=FALSE,message=FALSE}
#dev.off()
par(mar=c(2,2,2,2))
par(mfrow=c(2,1))
dis <- vegdist(t(Hfreq)); clus <- hclust(dis, "average"); plot(clus,cex=0.6,main="High Free Will Group"); 
rect.hclust(clus,10) # Inspect at five levels 


dis <- vegdist(t(Lfreq)); clus <- hclust(dis, "average"); plot(clus,cex=0.6,main="Low Free Will Group"); 
rect.hclust(clus,10) # Inspect at five levels 
```

#### Minimum Spanning Trees (MST)
Two groups looks similar in MST
```{r draw MST, echo=FALSE,message=FALSE}
#dev.off()
par(mar=c(2,2,2,2))
par(mfrow=c(1,1))
MST(Hfreq, "High") 
MST(Lfreq, "Low")
```

#### Association Network Graph
- Association Network were only plotted on those cue words that have correlation > 0.2
- The edge were colored according to correlatonal strenth between nodes, followed sequence of red, blue and grey representing correlation >0.5, >0.4, and else.
- The length of edge is weighted by correlational strength between nodes. 

Method: [Tutorial](http://stackoverflow.com/questions/19965600/igraph-r-how-to-create-correlation-network-with-only-strong-r-values)

```{r plot network,echo=FALSE,message=FALSE}
par(mfrow=c(1,1))
par(mar=c(1,1,1,1))
AssocNetPlot(Hfreq,"High")
AssocNetPlot(Lfreq,"Low")
#mtext("My 'Title' in a strange place", side = 3, line = 5, outer = TRUE)
```
      
      
##### Network parameters from HIGH and LOW groups were calculated:
```{r calculateing parameter,echo=FALSE,message=FALSE}
Hg<-graph(Hfreq)
Lg<-graph(Lfreq)
g<-graph(freq)

hAPL<-average.path.length(Hg); lAPL<-average.path.length(Lg)
hD<-diameter(Hg); lD<-diameter(Lg)
hCC<-transitivity(Hg); lCC<-transitivity(Lg)
hdegree<-mean(degree(Hg)) ;ldegree<- mean(degree(Lg))

I<-c(hAPL,lAPL,hD,lD,hCC,lCC,hdegree,ldegree)
compare<-matrix(I,nrow=4,byrow=T)
colnames(compare)<-c("High","Low")
rownames(compare)<-c("APL","Diameter","CC","Degree")
compare
```

##### Degree distribution
Most of node do not have a lot edges with other node. But there were some nodes have lots of edges with others. Those nodes were hubs in the network that connects between different clusters.  
```{r}
par(mar=c(2,2,2,2))
par(mfrow=c(2,2))
hist(degree(Hg),col="steelblue", main="Degree Histogram | High", xlab="degree/number of edge")
plot(degree.distribution(Hg),main="high",col="steelblue")

hist(degree(Lg),col="steelblue", main="Degree Histogram | Low", xlab="degree/number of edge")
plot(degree.distribution(Lg), main="low",col="steelblue")


```

#### Statistical text on association network graph
```{r bootstrap statistical test,echo=FALSE,message=FALSE}
NodeIndex<-1:dim(freq)[2]

comAPL<-matrix(rep(0,2000,),ncol=2);colnames(comAPL)<-c("High","Low")
comD<-matrix(rep(0,2000,),ncol=2);colnames(comD)<-c("High","Low")
comCC<-matrix(rep(0,2000,),ncol=2);colnames(comCC)<-c("High","Low")

set.seed(134)
for (i in 1:1000){
  ind<-sample(NodeIndex,32,replace=F)
  BHfreq<-Hfreq[,ind]
  BLfreq<-Lfreq[,ind]
  BHg<-graph(BHfreq)
  BLg<-graph(BLfreq)
  comAPL[i,1]=average.path.length(BHg)
  comAPL[i,2]=average.path.length(BLg)
  
  comD[i,1]=diameter(BHg)
  comD[i,2]=diameter(BLg)
  
  comCC[i,1]=transitivity(BHg)
  comCC[i,2]=transitivity(BLg)
  
  }

# Normality test
#hist(comAPL[,1],breaks=100)
#hist(comAPL[,2],breaks=100)
#qqnorm(comAPL[,1], col="blue")
#qqnorm(comAPL[,2], col="blue")


# t-test on average path length
#z.test(comAPL[,1],comAPL[,2],sigma.x=sd(comAPL[, 1]),sigma.y=sd(comAPL[, 1]))
APL<-t.test(comAPL[,1],comAPL[,2])
# t-test on diameter 
D<-t.test(comD[,1],comD[,2])
# t-test on cluster coefficient 
CC<-t.test(comCC[,1],comCC[,2])

```
##### Summary:
```{r stat summary,echo=FALSE,message=FALSE}
table<-data.frame(High.Mean=c( APL$estimate[[1]], D$estimate[[1]], CC$estimate[[1]] ),
              Low.Mean=c( APL$estimate[[2]], D$estimate[[2]], CC$estimate[[2]] ),
              p.value=c(format(APL$p.value, scientific=F,digits=1),
                        format(D$p.value, scientific=F,digits=5), 
                        format(CC$p.value, scientific=F, digits=6)))
table<-as.matrix(table)
rownames(table)<-c("APL","D","CC")
table
```

#### Detailed t-test result
```{r,echo=FALSE,message=FALSE,error=FALSE,warning=FALSE}
# t-test on average path length
t.test(comAPL[,1],comAPL[,2])
# t-test on diameter 
t.test(comD[,1],comD[,2])
# t-test on cluster coefficient 
t.test(comCC[,1],comCC[,2])
```
   
      
### Appendix
##### Statistical testing on association network:
  * "Second, we examined whether differences between the parameters of two association networks were statistically significant by applying the bootstrap method (Efron, 1979) to simulate partial random External and Internal networks and compared these networks (Kenett et al., 2013; Kenett, Anaki, et al., 2014). This procedure had a twofold rationale: 
      *  if the two networks truly differ from each other, then any sub-network consisting of the same nodes in both networks should also be different; and 
      *  the bootstrap method enables the generation of many simulated partial External and External networks, allowing for statistical examination of the difference between the two networks. 
  * In order to conduct the bootstrapping procedure, half of the cue words (nodes) were randomly chosen. Then partial external and internal networks were constructed separately using these random nodes, based on the entire sample. This method is known as the without replacement bootstrap (Bertail, 1997; Politis & Romano, 1994; Shao, 2003). Finally, for each partial AS and MC network, CC, ASPL,and D measures were computed. This procedure was simulated with 1000 realizations."

#### Terms:
[Degree](http://mathinsight.org/degree_distribution)  
[Unweighted Adjacency Matrix](http://mathinsight.org/definition/adjacency_matrix)  
[Small Word Network](http://mathinsight.org/small_world_network): Featured by large clustering coefficient and small average path length   
[Transitivity](http://mathinsight.org/evidence_additional_structure_real_networks#transitivity)  
[Transitivity math](http://mathinsight.org/definition/transitivity_graph)  
[Clustering Coefficient](http://mathinsight.org/definition/clustering_coefficient)  
[Free Will Scale Scoring Document](http://agencyandresponsibility.typepad.com/files/competing-free-will-and-responsibility-scales.pdf)   
[Minimum Spanning Tree Tutorial](http://cc.oulu.fi/~jarioksa/opetus/metodi/vegantutor.pdf)   
[Average Path Length](http://mathinsight.org/definition/network_mean_path_length)

#### Multi-Dimensional Emotional Scale of Empathy 
[Scoreing instruction](http://www.unh.edu/emotional_intelligence/EI%20Assets/Emapthy%20Scale/Empathy%20Article%202000.doc)
1. I cry easily when watching a sad movie.  	 
2. Certain pieces of music can really move me.	 
3. Seeing a hurt animal by the side of the road is very upsetting. 	 
4. R. I don't give others' feelings much thought.  		 
5. It makes me happy when I see people being nice to each other.	 
6. The suffering of others deeply disturbs me.
7. I always try to tune in to the feelings of those around me.	 
8. I get very upset when I see a young child who is being treated meanly.	
9. R. Too much is made of the suffering of pets or animals.	 
10. If someone is upset I get upset, too.	
11. When I'm with other people who are laughing I join in.	 
12. It makes me mad to see someone treated unjustly.	 
13. R. I rarely take notice when people treat each other warmly. 
14. I feel happy when I see people laughing and enjoying themselves.	 
15. It's easy for me to get carried away by other people's emotions. 
16. R. My feelings are my own and donâ€™t reflect how others feel.  
17. If a crowd gets excited about something so do I.			 
18. I feel good when I help someone out or do something nice for someone.  		 
19. I feel deeply for others.	 
20. R. I don't cry easily.  	 
21. I feel other people's pain. 
22. Seeing other people smile makes me smile.	
23. Being around happy people makes me feel happy, too.	 
24. TV or news stories about injured or sick children greatly upset me.				 
25. I cry at sad parts of the books I read.		 
26. Being around people who are depressed brings my mood down.	 
27. R. I find it annoying when people cry in public.	 
28. It hurts to see another person in pain.	 
29. I get a warm feeling for someone if I see them helping another person.  	 
30. I feel other people's joy.	 

Note: R indicates a reverse-scored item. To score the scale, change the scoring on the reverse-scored items (1=5, 2=4, 3=3, 4=2, 5=1). Add all the scores for the Total score and divide by 30.  Add the following items together for each scale, and divide by the number of items: Suffering ( 3, 5, 6, 8, 12, 18, 24, 28); Positive Sharing (14, 22, 23, 29, 30); Responsive Crying (1, 20, 25); Emotional Attention (4, 9, 13, 27); Feel for Others (10, 15, 16, 21); Emotional Contagion (11, 17).  Take the mean of these sub-scales to compute a General Empathy scale. 